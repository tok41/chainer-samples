{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE+GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.functions.loss.vae import gaussian_kl_divergence\n",
    "\n",
    "import chainer.optimizers as O\n",
    "import tqdm\n",
    "import time\n",
    "from IPython.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vaegan import Encoder, Decoder, Discriminator, EncDec\n",
    "from fauxtograph import get_paths, image_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "paths = get_paths('../../sample_images/sample_train/')\n",
    "print len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAEGAN(object):\n",
    "    def __init__(self, img_width=64, img_height=64, color_channels=3, encode_layers=[1000, 600, 300],\n",
    "                 decode_layers=[300, 800, 1000], disc_layers=[1000, 600, 300],\n",
    "                 kl_ratio=1.0, latent_width=500, flag_gpu=True, mode='convolution',\n",
    "                 enc_adam_alpha=0.0002, enc_adam_beta1=0.5, \n",
    "                 dec_adam_alpha=0.0002, dec_adam_beta1=0.5,\n",
    "                 disc_adam_alpha=0.0001, disc_adam_beta1=0.5,\n",
    "                 rectifier='clipped_relu', dropout_ratio=0.5):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.color_channels = color_channels\n",
    "        self.encode_layers = encode_layers\n",
    "        self.decode_layers = decode_layers\n",
    "        self.disc_layers = disc_layers\n",
    "        self.kl_ratio = kl_ratio\n",
    "        self.latent_width = latent_width\n",
    "        self.flag_gpu = flag_gpu\n",
    "        self.mode = mode\n",
    "        self.enc_adam_alpha = enc_adam_alpha\n",
    "        self.enc_adam_beta1 = enc_adam_beta1\n",
    "        self.dec_adam_alpha = dec_adam_alpha\n",
    "        self.dec_adam_beta1 = dec_adam_beta1\n",
    "        self.disc_adam_alpha = disc_adam_alpha\n",
    "        self.disc_adam_beta1 = disc_adam_beta1\n",
    "        self.rectifier = rectifier\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.enc = Encoder(img_width=self.img_width, img_height=self.img_height, \n",
    "                           color_channels=self.color_channels, encode_layers=self.encode_layers,\n",
    "                           latent_width=self.latent_width, mode=self.mode)\n",
    "        self.dec = Decoder(img_width=self.img_width,img_height=self.img_height,\n",
    "                           color_channels=self.color_channels, decode_layers=self.decode_layers,\n",
    "                           latent_width=self.latent_width, mode=self.mode)\n",
    "        self.disc = Discriminator(img_width=self.img_width, img_height=self.img_height,\n",
    "                                  color_channels=self.color_channels, disc_layers=self.disc_layers,\n",
    "                                  latent_width=self.latent_width, mode=self.mode)\n",
    "        if self.flag_gpu:\n",
    "            self.enc = self.enc.to_gpu()\n",
    "            self.dec = self.dec.to_gpu()\n",
    "            self.disc = self.disc.to_gpu()\n",
    "\n",
    "        self.enc_opt = O.Adam(alpha=self.enc_adam_alpha, beta1=self.enc_adam_beta1)\n",
    "        self.dec_opt = O.Adam(alpha=self.dec_adam_alpha, beta1=self.dec_adam_beta1)\n",
    "        self.disc_opt = O.Adam(alpha=self.disc_adam_alpha, beta1=self.disc_adam_beta1)\n",
    "\n",
    "    def _save_meta(self, filepath):\n",
    "        if not os.path.exists(os.path.dirname(filepath)):\n",
    "            os.makedirs(os.path.dirname(filepath))\n",
    "        d = self.__dict__.copy()\n",
    "        poplist = ['enc', 'dec', 'disc', 'enc_opt', 'dec_opt', 'disc_opt', ]\n",
    "        for name in poplist:\n",
    "            d.pop(name)\n",
    "        meta = json.dumps(d)\n",
    "        with open(filepath+'.json', 'wb') as f:\n",
    "            f.write(meta)\n",
    "\n",
    "    def _encode(self, data, test=False):\n",
    "        x = self.enc(data, test=test)\n",
    "        mean, ln_var = F.split_axis(x, 2, 1)\n",
    "        samp = np.random.standard_normal(mean.data.shape).astype('float32')\n",
    "        samp = Variable(samp)\n",
    "        if self.flag_gpu:\n",
    "            samp.to_gpu()\n",
    "        z = samp * F.exp(0.5*ln_var) + mean\n",
    "\n",
    "        return z, mean, ln_var\n",
    "\n",
    "    def _decode(self, z, test=False):\n",
    "        x = self.dec(z, test=test, rectifier=self.rectifier)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _forward(self, batch, test=False):\n",
    "\n",
    "        # TrainingSetのEncodeとDecode\n",
    "        encoded, means, ln_vars = self._encode(batch, test=test)\n",
    "        rec = self._decode(encoded, test=test)\n",
    "        normer = reduce(lambda x, y: x*y, means.data.shape) # データ数\n",
    "        kl_loss = F.gaussian_kl_divergence(means, ln_vars)/normer\n",
    "\n",
    "        # zのサンプル\n",
    "        samp_p = np.random.standard_normal(means.data.shape).astype('float32')\n",
    "        z_p = chainer.Variable(samp_p)\n",
    "\n",
    "        if self.flag_gpu:\n",
    "            z_p.to_gpu()\n",
    "\n",
    "        rec_p = self._decode(z_p)\n",
    "\n",
    "        disc_rec, conv_layer_rec = self.disc(rec, test=test, dropout_ratio=self.dropout_ratio)\n",
    "\n",
    "        disc_batch, conv_layer_batch = self.disc(batch, test=test, dropout_ratio=self.dropout_ratio)\n",
    "\n",
    "        disc_x_p, conv_layer_x_p = self.disc(rec_p, test=test, dropout_ratio=self.dropout_ratio)\n",
    "\n",
    "        dif_l = F.mean_squared_error(conv_layer_rec, conv_layer_batch)\n",
    "\n",
    "        return kl_loss, dif_l, disc_rec, disc_batch, disc_x_p\n",
    "\n",
    "    def transform(self, data, test=False):\n",
    "        #make sure that data has the right shape.\n",
    "        if not type(data) == Variable:\n",
    "            if len(data.shape) < 4:\n",
    "                data = data[np.newaxis]\n",
    "            if len(data.shape) != 4:\n",
    "                raise TypeError(\"Invalid dimensions for image data. Dim = %s.\\\n",
    "                     Must be 4d array.\" % str(data.shape))\n",
    "            if data.shape[1] != self.color_channels:\n",
    "                if data.shape[-1] == self.color_channels:\n",
    "                    data = data.transpose(0, 3, 1, 2)\n",
    "                else:\n",
    "                    raise TypeError(\"Invalid dimensions for image data. Dim = %s\"\n",
    "                                    % str(data.shape))\n",
    "            data = Variable(data)\n",
    "        else:\n",
    "            if len(data.data.shape) < 4:\n",
    "                data.data = data.data[np.newaxis]\n",
    "            if len(data.data.shape) != 4:\n",
    "                raise TypeError(\"Invalid dimensions for image data. Dim = %s.\\\n",
    "                     Must be 4d array.\" % str(data.data.shape))\n",
    "            if data.data.shape[1] != self.color_channels:\n",
    "                if data.data.shape[-1] == self.color_channels:\n",
    "                    data.data = data.data.transpose(0, 3, 1, 2)\n",
    "                else:\n",
    "                    raise TypeError(\"Invalid dimensions for image data. Dim = %s\"\n",
    "                                    % str(data.shape))\n",
    "\n",
    "        # Actual transformation.\n",
    "        if self.flag_gpu:\n",
    "            data.to_gpu()\n",
    "        z = self._encode(data, test=test)[0]\n",
    "\n",
    "        z.to_cpu()\n",
    "\n",
    "        return z.data\n",
    "\n",
    "    def inverse_transform(self, data, test=False):\n",
    "        if not type(data) == Variable:\n",
    "            if len(data.shape) < 2:\n",
    "                data = data[np.newaxis]\n",
    "            if len(data.shape) != 2:\n",
    "                raise TypeError(\"Invalid dimensions for latent data. Dim = %s.\\\n",
    "                     Must be a 2d array.\" % str(data.shape))\n",
    "            data = Variable(data)\n",
    "\n",
    "        else:\n",
    "            if len(data.data.shape) < 2:\n",
    "                data.data = data.data[np.newaxis]\n",
    "            if len(data.data.shape) != 2:\n",
    "                raise TypeError(\"Invalid dimensions for latent data. Dim = %s.\\\n",
    "                     Must be a 2d array.\" % str(data.data.shape))\n",
    "        assert data.data.shape[-1] == self.latent_width,\\\n",
    "            \"Latent shape %d != %d\" % (data.data.shape[-1], self.latent_width)\n",
    "\n",
    "        if self.flag_gpu:\n",
    "            data.to_gpu()\n",
    "        out = self._decode(data, test=test)\n",
    "\n",
    "        out.to_cpu()\n",
    "\n",
    "        if self.mode == 'linear':\n",
    "            final = out.data\n",
    "        else:\n",
    "            final = out.data.transpose(0, 2, 3, 1)\n",
    "\n",
    "        return final\n",
    "\n",
    "    def load_images(self, filepaths):\n",
    "        def read(fname):\n",
    "            im = Image.open(fname)\n",
    "            im = np.float32(im)\n",
    "            return im/255.\n",
    "        x_all = np.array([read(fname) for fname in tqdm.tqdm(filepaths)])\n",
    "        x_all = x_all.astype('float32')\n",
    "        if self.mode == 'convolution':\n",
    "            x_all = x_all.transpose(0, 3, 1, 2)\n",
    "        print(\"Image Files Loaded!\")\n",
    "        return x_all\n",
    "\n",
    "    def fit(self, img_data, gamma=1.0, save_freq=-1, pic_freq=-1, n_epochs=100, batch_size=50,\n",
    "            weight_decay=True,  model_path='./VAEGAN_training_model/', img_path='./VAEGAN_training_images/',\n",
    "            img_out_width=10, mirroring=False):\n",
    "        width = img_out_width\n",
    "        self.enc_opt.setup(self.enc)\n",
    "        self.dec_opt.setup(self.dec)\n",
    "        self.disc_opt.setup(self.disc)\n",
    "\n",
    "        if weight_decay:\n",
    "            self.enc_opt.add_hook(chainer.optimizer.WeightDecay(0.00001))\n",
    "            self.dec_opt.add_hook(chainer.optimizer.WeightDecay(0.00001))\n",
    "            self.disc_opt.add_hook(chainer.optimizer.WeightDecay(0.00001))\n",
    "\n",
    "        n_data = img_data.shape[0]\n",
    "\n",
    "        batch_iter = list(range(0, n_data, batch_size))\n",
    "        n_batches = len(batch_iter)\n",
    "\n",
    "        c_samples = np.random.standard_normal((width, self.latent_width)).astype(np.float32)\n",
    "        save_counter = 0\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            print('epoch: %i' % epoch)\n",
    "            t1 = time.time()\n",
    "            indexes = np.random.permutation(n_data)\n",
    "            sum_l_enc = 0.\n",
    "            sum_l_dec = 0.\n",
    "            sum_l_disc = 0.\n",
    "\n",
    "            sum_l_gan = 0.\n",
    "            sum_l_like = 0.\n",
    "            sum_l_prior = 0.\n",
    "            count = 0\n",
    "            for i in tqdm.tqdm(batch_iter):\n",
    "                x = img_data[indexes[i: i + batch_size]]\n",
    "                size = x.shape[0]\n",
    "                if mirroring:\n",
    "                    for j in range(size):\n",
    "                        if np.random.randint(2):\n",
    "                            x[j, :, :, :] = x[j, :, :, ::-1]\n",
    "                x_batch = Variable(x)\n",
    "                zeros = Variable(np.zeros(size, dtype=np.int32))\n",
    "                ones = Variable(np.ones(size, dtype=np.int32))\n",
    "\n",
    "                if self.flag_gpu:\n",
    "                    x_batch.to_gpu()\n",
    "                    zeros.to_gpu()\n",
    "                    ones.to_gpu()\n",
    "\n",
    "                # kl_loss : VAE中間表現のKL正則化ロス\n",
    "                # dif_l : Discriminatorの中間層出力のMSE(学習データセットと再構成画像の中間出力のMSE)\n",
    "                # disc_{rec, batch, samp} : Discriminator出力(2次元)\n",
    "                kl_loss, dif_l, disc_rec, disc_batch, disc_samp = self._forward(x_batch)\n",
    "\n",
    "                # Discriminator出力のloss計算\n",
    "                L_batch_GAN = F.softmax_cross_entropy(disc_batch, ones)\n",
    "                L_rec_GAN = F.softmax_cross_entropy(disc_rec, zeros)\n",
    "                L_samp_GAN = F.softmax_cross_entropy(disc_samp, zeros)\n",
    "\n",
    "                l_gan = (L_batch_GAN + L_rec_GAN + L_samp_GAN)/3.\n",
    "                l_like = dif_l\n",
    "                l_prior = kl_loss\n",
    "\n",
    "                enc_loss = self.kl_ratio*l_prior + l_like\n",
    "                dec_loss = gamma*l_like - l_gan\n",
    "                disc_loss = l_gan\n",
    "\n",
    "                self.enc_opt.zero_grads()\n",
    "                enc_loss.backward()\n",
    "                self.enc_opt.update()\n",
    "\n",
    "                self.dec_opt.zero_grads()\n",
    "                dec_loss.backward()\n",
    "                self.dec_opt.update()\n",
    "\n",
    "                self.disc_opt.zero_grads()\n",
    "                disc_loss.backward()\n",
    "                self.disc_opt.update()\n",
    "\n",
    "                sum_l_enc += enc_loss.data\n",
    "                sum_l_dec += dec_loss.data\n",
    "                sum_l_disc += disc_loss.data\n",
    "\n",
    "                sum_l_gan += l_gan.data\n",
    "                sum_l_like += l_like.data\n",
    "                sum_l_prior += l_prior.data\n",
    "                count += 1\n",
    "\n",
    "                plot_data = img_data[indexes[:width]]\n",
    "                if pic_freq > 0:\n",
    "                    assert type(pic_freq) == int, \"pic_freq must be an integer.\"\n",
    "                    if count % pic_freq == 0:\n",
    "                        fig = self._plot_img(\n",
    "                            plot_data,\n",
    "                            c_samples,\n",
    "                            img_path=img_path,\n",
    "                            epoch=epoch\n",
    "                        )\n",
    "                        display(fig)\n",
    "\n",
    "            if save_freq > 0:\n",
    "                save_counter += 1\n",
    "                assert type(save_freq) == int, \"save_freq must be an integer.\"\n",
    "                if epoch % save_freq == 0:\n",
    "                    name = \"vaegan_epoch%s\" % str(epoch)\n",
    "                    if save_counter == 1:\n",
    "                        save_meta = True\n",
    "                    else:\n",
    "                        save_meta = False\n",
    "                    self.save(model_path, name, save_meta=save_meta)\n",
    "                    fig = self._plot_img(\n",
    "                        plot_data,\n",
    "                        c_samples,\n",
    "                        img_path=img_path,\n",
    "                        epoch=epoch,\n",
    "                        batch=n_batches,\n",
    "                        save_pic=True\n",
    "                        )\n",
    "            sum_l_enc /= n_batches\n",
    "            sum_l_dec /= n_batches\n",
    "            sum_l_disc /= n_batches\n",
    "            sum_l_gan /= n_batches\n",
    "            sum_l_like /= n_batches\n",
    "            sum_l_prior /= n_batches\n",
    "            msg = \"enc_loss = {0}, dec_loss = {1} , disc_loss = {2}\"\n",
    "            msg2 = \"gan_loss = {0}, sim_loss = {1}, kl_loss = {2}\"\n",
    "            print(msg.format(sum_l_enc, sum_l_dec, sum_l_disc))\n",
    "            print(msg2.format(sum_l_gan, sum_l_like, sum_l_prior))\n",
    "            t_diff = time.time()-t1\n",
    "            print(\"time: %f\\n\\n\" % t_diff)\n",
    "\n",
    "    def _plot_img(self, img_data, samples, img_path='./', epoch=1, batch=1, save_pic=False):\n",
    "\n",
    "        if samples.shape[0] < 10:\n",
    "            width = samples.shape[0]\n",
    "        else:\n",
    "            width = 10\n",
    "\n",
    "        x = Variable(samples[:width])\n",
    "        y = Variable(np.random.standard_normal((width, self.latent_width)).astype(np.float32))\n",
    "        z = img_data[:width]\n",
    "        if self.flag_gpu:\n",
    "            x.to_gpu()\n",
    "            y.to_gpu()\n",
    "        x_pics = self._decode(x)\n",
    "        y_pics = self.dec(y)\n",
    "        z_data = self.transform(z)\n",
    "        z_rec = self.inverse_transform(z_data)\n",
    "        x_pics.to_cpu()\n",
    "        y_pics.to_cpu()\n",
    "\n",
    "        fig = plt.figure(figsize=(16.0, 6.0))\n",
    "\n",
    "        x_pics = x_pics.data.transpose(0, 2, 3, 1)\n",
    "        y_pics = y_pics.data.transpose(0, 2, 3, 1)\n",
    "        z = z.transpose(0, 2, 3, 1)\n",
    "\n",
    "        for i in range(width):\n",
    "            plt.subplot(4, width, i+1)\n",
    "            plt.imshow(z[i])\n",
    "            plt.axis(\"off\")\n",
    "        for i in range(width):\n",
    "            plt.subplot(4, width, width+i+1)\n",
    "            plt.imshow(z_rec[i])\n",
    "            plt.axis(\"off\")\n",
    "        for i in range(width):\n",
    "            plt.subplot(4, width, 2*width+i+1)\n",
    "            plt.imshow(x_pics[i])\n",
    "            plt.axis(\"off\")\n",
    "        for i in range(width):\n",
    "            plt.subplot(4, width, 3*width+i+1)\n",
    "            plt.imshow(y_pics[i])\n",
    "            plt.axis(\"off\")\n",
    "        if save_pic:\n",
    "            if img_path[-1] != '/':\n",
    "                img_path += '/'\n",
    "            if not os.path.exists(os.path.dirname(img_path)):\n",
    "                os.makedirs(os.path.dirname(img_path))\n",
    "            save_str = 'image_gan_epoch%d_batch%d.png' % (epoch, batch)\n",
    "            plt.savefig(os.path.join(img_path, save_str))\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def save(self, path, name, save_meta=True):\n",
    "        _save_model(self.enc, str(path), \"%s_enc\" % str(name))\n",
    "        _save_model(self.dec, str(path), \"%s_dec\" % str(name))\n",
    "        _save_model(self.disc, str(path), \"%s_disc\" % str(name))\n",
    "        _save_model(self.enc_opt, str(path), \"%s_enc_opt\" % str(name))\n",
    "        _save_model(self.dec_opt, str(path), \"%s_dec_opt\" % str(name))\n",
    "        _save_model(self.disc_opt, str(path), \"%s_disc_opt\" % str(name))\n",
    "        if save_meta:\n",
    "            self._save_meta(os.path.join(path, \"%s_meta\" % str(name)))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, enc, dec, disc, enc_opt, dec_opt, disc_opt, meta, flag_gpu=None):\n",
    "        mess = \"Model file {0} does not exist. Please check the file path.\"\n",
    "        assert os.path.exists(enc), mess.format(enc)\n",
    "        assert os.path.exists(dec), mess.format(dec)\n",
    "        assert os.path.exists(disc), mess.format(disc)\n",
    "        assert os.path.exists(dec_opt), mess.format(dec_opt)\n",
    "        assert os.path.exists(disc_opt), mess.format(disc_opt)\n",
    "        assert os.path.exists(meta), mess.format(meta)\n",
    "        with open(meta, 'r') as f:\n",
    "            meta = json.load(f)\n",
    "        if flag_gpu is not None:\n",
    "            meta['flag_gpu'] = flag_gpu\n",
    "\n",
    "        loaded_class = cls(**meta)\n",
    "\n",
    "        serializers.load_hdf5(enc, loaded_class.enc)\n",
    "        serializers.load_hdf5(dec, loaded_class.dec)\n",
    "        serializers.load_hdf5(disc, loaded_class.disc)\n",
    "        loaded_class.enc_opt.setup(loaded_class.enc)\n",
    "        loaded_class.dec_opt.setup(loaded_class.dec)\n",
    "        loaded_class.disc_opt.setup(loaded_class.disc)\n",
    "        serializers.load_hdf5(enc_opt, loaded_class.enc_opt)\n",
    "        serializers.load_hdf5(dec_opt, loaded_class.dec_opt)\n",
    "        serializers.load_hdf5(disc_opt, loaded_class.disc_opt)\n",
    "\n",
    "        if meta['flag_gpu']:\n",
    "            loaded_class.enc.to_gpu()\n",
    "            loaded_class.dec.to_gpu()\n",
    "            loaded_class.disc.to_gpu()\n",
    "\n",
    "        return loaded_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vg = VAEGAN(img_width=96, img_height=96, flag_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 644.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Files Loaded!\n",
      "image_data_shape = (200, 3, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 画像ファイルのロード、正規化、transpose\n",
    "x_all = vg.load_images(paths)\n",
    "print 'image_data_shape = {}'.format(x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_path = './out/model/'\n",
    "im_path = './out/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:05<00:00, 16.09s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_loss = 2.28291869164, dec_loss = 0.898291453719 , disc_loss = 0.878019556403\n",
      "gan_loss = 0.878019556403, sim_loss = 1.77631101012, kl_loss = 0.506607651711\n",
      "time: 65.357756\n",
      "\n",
      "\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:03<00:00, 16.17s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name '_save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-52fdd1f25433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmirroring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-faa1da7cf3e7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, img_data, gamma, save_freq, pic_freq, n_epochs, batch_size, weight_decay, model_path, img_path, img_out_width, mirroring)\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                         \u001b[0msave_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     fig = self._plot_img(\n\u001b[1;32m    286\u001b[0m                         \u001b[0mplot_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-faa1da7cf3e7>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, name, save_meta)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s_enc\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s_dec\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s_disc\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name '_save_model' is not defined"
     ]
    }
   ],
   "source": [
    "vg.fit(x_all, save_freq=2, pic_freq=30, n_epochs=2, model_path = m_path, img_path=im_path, mirroring=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape = 10, vg.latent_width\n",
    "random_data = np.random.standard_normal(shape).astype('f')*3.\n",
    "images = vg.inverse_transform(random_data, test=True)\n",
    "plt.figure(figsize=(16,3))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
