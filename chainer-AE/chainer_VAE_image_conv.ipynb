{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#オートエンコーダー（一般画像）\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>オートエンコーダー（一般画像）</a></div><div class=\"lev2\"><a href=\"#GPU設定\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>GPU設定</a></div><div class=\"lev2\"><a href=\"#データのロード\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>データのロード</a></div><div class=\"lev2\"><a href=\"#学習パラメータの設定\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>学習パラメータの設定</a></div><div class=\"lev2\"><a href=\"#モデルの定義\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>モデルの定義</a></div><div class=\"lev2\"><a href=\"#Optimizerの設定\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Optimizerの設定</a></div><div class=\"lev2\"><a href=\"#訓練の実行\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>訓練の実行</a></div><div class=\"lev2\"><a href=\"#結果の可視化\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>結果の可視化</a></div><div class=\"lev2\"><a href=\"#Convolution層のフィルタを可視化\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Convolution層のフィルタを可視化</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オートエンコーダー（一般画像）\n",
    "* アニメ顔とかのオートエンコーダーを作ってみる\n",
    "* 中間層にKL正規化項を入れ、変分AEにしている\n",
    "* ネットワークはConvolution - Deconcolutionネットワークを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import math\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.functions.loss.vae import gaussian_kl_divergence\n",
    "\n",
    "import six\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chainer exampleに付属のdata.pyをimportする. mnistのダウンロードのため\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_flag = 0\n",
    "if gpu_flag >= 0:\n",
    "    cuda.check_cuda_available()\n",
    "xp = cuda.cupy if gpu_flag >= 0 else np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img_size\n",
    "size = 96\n",
    "# image path\n",
    "image_dir = \"./images/celeb_sample\"\n",
    "#image_dir = \"./images/sample/\"\n",
    "# load images\n",
    "fs = os.listdir(image_dir)\n",
    "dataset = []\n",
    "for fn in fs:\n",
    "    f = open('%s/%s'%(image_dir,fn), 'rb')\n",
    "    img_bin = f.read()\n",
    "    img = np.asarray(Image.open(StringIO(img_bin)).convert('RGB')).astype(np.float32).transpose(2, 0, 1)\n",
    "    dataset.append(img)\n",
    "    f.close()\n",
    "dataset = np.asarray(dataset)\n",
    "print(\"num_of_images : %s\"%dataset.shape[0])\n",
    "\n",
    "## 画素が（-1~1）の範囲に収まるように調整する関数の定義\n",
    "def clip_img(x):\n",
    "    return np.float32(-1 if x<(-1) else (1 if x>1 else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_img_mc(data):\n",
    "    size = 96\n",
    "    n = data.shape[0]\n",
    "    plt.figure(figsize=(n*2, 2))\n",
    "    cnt = 1\n",
    "    for idx in np.arange(n):\n",
    "        plt.subplot(1, n, cnt)\n",
    "        X, Y = np.meshgrid(range(size),range(size))\n",
    "        Z = data[idx].reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "        Z = Z[::-1,:]             # flip vertical\n",
    "        plt.xlim(0,size)\n",
    "        plt.ylim(0,size)\n",
    "        plt.pcolor(X, Y, Z)\n",
    "        plt.gray()\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()\n",
    "def draw_img_rgb(data):\n",
    "    size = 96\n",
    "    n = data.shape[0]\n",
    "    plt.figure(figsize=(n*2, 2))\n",
    "    data /= data.max()\n",
    "    cnt = 1\n",
    "    for idx in np.arange(n):\n",
    "        plt.subplot(1, n, cnt)\n",
    "        tmp = data[idx,:,:,:].transpose(1,2,0)\n",
    "        plt.imshow(tmp)\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()\n",
    "draw_img_rgb( dataset[np.random.permutation( dataset.shape[0] )[:10]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = dataset.shape[0]\n",
    "train_rate = 0.7\n",
    "N_train = int(N*train_rate)\n",
    "N_test = N - N_train\n",
    "print('N_dataset={}, N_train={}, N_test={}'.format(N, N_train, N_test))\n",
    "\n",
    "# 正規化(0~1に)\n",
    "dataset /= 255\n",
    "# 訓練データとテストデータに分割\n",
    "x_train, x_test = np.split(dataset,   [N_train])\n",
    "print x_train.shape\n",
    "## 訓練データとテストデータは決定論的に分割（単純に最初から７割をくんれんデータにして、残りをテストデータ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100 # ミニバッチのサイズ\n",
    "n_epoch = 200     # epoch数\n",
    "n_latent = 10000   # 潜在変数の次元(DCGANで言うところのプライヤーベクトルの次元)\n",
    "beta = 1.0   # KL正則化項の重み\n",
    "conv_size = 512  # convolution層の最大チャネルサイズ\n",
    "\n",
    "# Optimizer(Adam)\n",
    "al = 0.0001 # 0.001だと学習が安定しなかった（発散して、nanが出る。正則化項のlossで）\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "\n",
    "# モデルの出力インターバル\n",
    "model_interval = 20\n",
    "# モデルファイルの出力先\n",
    "out_model_dir = './out/out_models_celeb_vae_01'\n",
    "try:\n",
    "    os.mkdir(out_model_dir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(chainer.Chain):\n",
    "    \"\"\"AutoEncoder\"\"\"\n",
    "    def __init__(self, n_latent=100, input_size=96, input_ch=3, output_ch=512):\n",
    "        self.input_ch = input_ch\n",
    "        self.output_ch = output_ch\n",
    "        self.input_size = input_size\n",
    "        self.out_size = input_size/(2**4)\n",
    "        super(VAE, self).__init__(\n",
    "            ## ネットワーク構造の定義\n",
    "            # encoder\n",
    "            c0 = L.Convolution2D(self.input_ch, self.output_ch/8, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.input_ch)),\n",
    "            c1 = L.Convolution2D(self.output_ch/8, self.output_ch/4, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/8)),\n",
    "            c2 = L.Convolution2D(self.output_ch/4, self.output_ch/2, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/4)),\n",
    "            c3 = L.Convolution2D(self.output_ch/2, self.output_ch, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/2)),\n",
    "            l4_mu = L.Linear(self.out_size*self.out_size*self.output_ch, n_latent, wscale=0.02*math.sqrt(self.out_size*self.out_size*self.output_ch)),\n",
    "            l4_var = L.Linear(self.out_size*self.out_size*self.output_ch, n_latent, wscale=0.02*math.sqrt(self.out_size*self.out_size*self.output_ch)),\n",
    "            bne0 = L.BatchNormalization(self.output_ch/8),\n",
    "            bne1 = L.BatchNormalization(self.output_ch/4),\n",
    "            bne2 = L.BatchNormalization(self.output_ch/2),\n",
    "            bne3 = L.BatchNormalization(self.output_ch),\n",
    "            # decoder\n",
    "            l0z = L.Linear(n_latent, self.out_size*self.out_size*self.output_ch, wscale=0.02*math.sqrt(n_latent)),\n",
    "            dc1 = L.Deconvolution2D(self.output_ch, self.output_ch/2, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch)),\n",
    "            dc2 = L.Deconvolution2D(self.output_ch/2, self.output_ch/4, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/2)),\n",
    "            dc3 = L.Deconvolution2D(self.output_ch/4, self.output_ch/8, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/4)),\n",
    "            dc4 = L.Deconvolution2D(self.output_ch/8, self.input_ch, 4, stride=2, pad=1, wscale=0.02*math.sqrt(4*4*self.output_ch/8)),\n",
    "            bnd0l = L.BatchNormalization(self.out_size*self.out_size*self.output_ch),\n",
    "            bnd0 = L.BatchNormalization(self.output_ch),\n",
    "            bnd1 = L.BatchNormalization(self.output_ch/2),\n",
    "            bnd2 = L.BatchNormalization(self.output_ch/4),\n",
    "            bnd3 = L.BatchNormalization(self.output_ch/8),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, sigmoid=True):\n",
    "        \"\"\"AutoEncoder\"\"\"\n",
    "        # 下記、encodeとdecodeの中身をこの中に書いても良いがencodeとｄｅｃｏｄｅは他でも使うので再利用性を高めるために\n",
    "        return self.decode(self.encode(x)[0], sigmoid)\n",
    "\n",
    "    def encode(self, x, test=False):\n",
    "        # 推論モデル, 中間表現のベクトルqを学習\n",
    "        h = F.relu(self.bne0(self.c0(x)))\n",
    "        h = F.relu(self.bne1(self.c1(h), test=test))\n",
    "        h = F.relu(self.bne2(self.c2(h), test=test))\n",
    "        h = F.relu(self.bne3(self.c3(h), test=test))\n",
    "        mu = (self.l4_mu(h))\n",
    "        var = (self.l4_var(h))\n",
    "        return mu, var\n",
    "\n",
    "    def decode(self, z, sigmoid=True, test=False):\n",
    "        # 中間表現ベクトルqを入力として(z), 画像を生成\n",
    "        h = F.reshape(F.relu(self.bnd0l(self.l0z(z), test=test)), (z.data.shape[0], self.output_ch, self.out_size, self.out_size))\n",
    "        h = F.relu(self.bnd1(self.dc1(h), test=test))\n",
    "        h = F.relu(self.bnd2(self.dc2(h), test=test))\n",
    "        h = F.relu(self.bnd3(self.dc3(h), test=test))\n",
    "        x = (self.dc4(h))\n",
    "        if sigmoid:\n",
    "            return F.sigmoid(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def get_loss_func(self, C=1.0, k=1, train=True):\n",
    "        \"\"\"Get loss function of VAE.\n",
    "        Args:\n",
    "            C (int): Usually this is 1.0. Can be changed to control the\n",
    "                second term of ELBO bound, which works as regularization.\n",
    "            k (int): Number of Monte Carlo samples used in encoded vector.\n",
    "            train (bool): If true loss_function is used for training.\n",
    "        \"\"\"\n",
    "        def lf(x):\n",
    "            mu, ln_var = self.encode(x)\n",
    "            batchsize = len(mu.data)\n",
    "            # reconstruction loss\n",
    "            rec_loss = 0\n",
    "            for l in six.moves.range(k):\n",
    "                z = F.gaussian(mu, ln_var)\n",
    "                rec_loss += F.bernoulli_nll(x, self.decode(z, sigmoid=False)) / (k * batchsize)\n",
    "                #rec_loss += F.mean_squared_error(x, self.decode(z)) / (k)\n",
    "            self.rec_loss = rec_loss\n",
    "            # reguralization\n",
    "            self.loss = self.rec_loss + C * gaussian_kl_divergence(mu, ln_var) / batchsize\n",
    "            return self.loss\n",
    "        return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizerの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "model = VAE(input_size=size, n_latent=n_latent, output_ch=conv_size)\n",
    "if gpu_flag >= 0:\n",
    "    cuda.get_device(gpu_flag).use()\n",
    "    model.to_gpu()\n",
    "xp = np if gpu_flag < 0 else cuda.cupy\n",
    "\n",
    "# Optimizerを定義する\n",
    "optimizer = optimizers.Adam(alpha=al, beta1=b1, beta2=b2)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "recloss_arr = []\n",
    "for epoch in six.moves.range(1, n_epoch + 1):\n",
    "    print('epoch', epoch)\n",
    "    \n",
    "    # training\n",
    "    ## 訓練データのsampler\n",
    "    perm = np.random.permutation(N_train)\n",
    "    ## lossのbuffer\n",
    "    sum_loss = 0       # total loss\n",
    "    sum_rec_loss = 0   # reconstruction loss\n",
    "    ## バッチ学習\n",
    "    for i in six.moves.range(0, N_train, batchsize):\n",
    "        x = chainer.Variable(xp.asarray(x_train[perm[i:i + batchsize]])) # バッチ分のデータの抽出\n",
    "        \n",
    "        model.zerograds()\n",
    "        loss = model.get_loss_func(C=beta)(x)\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(model.loss.data) * len(x.data)\n",
    "        sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n",
    "\n",
    "    print('train mean loss={}, mean reconstruction loss={}'.format(sum_loss / N, sum_rec_loss / N))\n",
    "    loss_arr.append(float(sum_loss)/N_train)\n",
    "    recloss_arr.append(float(sum_rec_loss)/N_train)\n",
    "\n",
    "    # モデルの保存\n",
    "    if epoch%model_interval==0:\n",
    "        serializers.save_hdf5(\"%s/model_VAE_%05d.h5\"%(out_model_dir, epoch), model)\n",
    "# モデルの保存(最終モデル)\n",
    "if epoch%model_interval!=0:\n",
    "    serializers.save_hdf5(\"%s/model_VAE_%05d.h5\"%(out_model_dir, epoch), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(range(len(loss_arr)), loss_arr, color=\"#0000FF\", label=\"total_loss\")\n",
    "plt.plot(range(len(recloss_arr)), recloss_arr, color=\"#FF0000\", label=\"rec_loss\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 描画テスト (Closed test)\n",
    "test_ind = np.random.permutation(N_train)[:10]\n",
    "print test_ind\n",
    "test = chainer.Variable(xp.asarray(x_train[test_ind]), volatile='on')\n",
    "y = model(test)\n",
    "\n",
    "print \"input image\"\n",
    "draw_img_rgb(x_train[test_ind])\n",
    "\n",
    "print \"reconstruction image\"\n",
    "draw_img_rgb(y.data.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 描画テスト (Open test) \n",
    "test_ind = np.random.permutation(N_test)[:10]\n",
    "print test_ind\n",
    "test = chainer.Variable(xp.asarray(x_test[test_ind]), volatile='on')\n",
    "y = model(test)\n",
    "\n",
    "print \"input image\"\n",
    "draw_img_rgb(x_test[test_ind])\n",
    "\n",
    "print \"reconstruction image\"\n",
    "draw_img_rgb(y.data.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 描画テスト (Open test, 固定画像) \n",
    "#test_ind = np.arange(70,80)\n",
    "test_ind = [1, 4, 6, 8, 42, 70, 76, 79, 153, 156]\n",
    "print test_ind\n",
    "test = chainer.Variable(xp.asarray(x_test[test_ind]), volatile='on')\n",
    "y = model(test)\n",
    "\n",
    "print \"input image\"\n",
    "draw_img_rgb(x_test[test_ind])\n",
    "\n",
    "print \"reconstruction image\"\n",
    "draw_img_rgb(y.data.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw images from randomly sampled z\n",
    "z = chainer.Variable(xp.random.normal(0, 1, (10, n_latent)).astype(np.float32))\n",
    "x = model.decode(z)\n",
    "print \"decode image from random vector\"\n",
    "draw_img_rgb(x.data.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution層のフィルタを可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_img_filter(data):\n",
    "    size = data.shape[3]\n",
    "    n = data.shape[0]\n",
    "    n_col = int(math.ceil(n / 15)+1)\n",
    "    img_data = data.get()\n",
    "    plt.figure(figsize=(10*2, n_col*2))\n",
    "    img_data /= img_data.max()\n",
    "    cnt = 1\n",
    "    for idx in np.arange(n):\n",
    "        plt.subplot(n_col, 15, cnt)\n",
    "        tmp = img_data[idx,:,:,:].transpose(1,2,0)\n",
    "        plt.imshow(tmp)\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 入力層側\n",
    "draw_img_filter(model.c0.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 出力層側\n",
    "draw_img_filter(model.dc4.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
