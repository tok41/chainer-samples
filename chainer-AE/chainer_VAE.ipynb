{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChainerでVAEを書いてみる\n",
    "* 以下のページを参考に\n",
    "  * https://github.com/RyotaKatoh/chainer-Variational-AutoEncoder\n",
    "* VAEについては以下を参照した\n",
    "  * http://papers.nips.cc/paper/5352-semi-supervised-learning-with-deep-generative-models.pdf\n",
    "  * http://deeplearning.jp/wp-content/uploads/2014/04/dl_hacks2015-04-21-iwasawa1.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.functions.loss.vae import gaussian_kl_divergence\n",
    "\n",
    "import six\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# chainer exampleに付属のdata.pyをimportする. mnistのダウンロードのため\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu_flag = 0\n",
    "if gpu_flag >= 0:\n",
    "    cuda.check_cuda_available()\n",
    "xp = cuda.cupy if gpu_flag >= 0 else np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータのダウンロードといくつかプロットして確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 手書き数字データを描画する関数\n",
    "# 複数の画像配列になっているdata列を描画する\n",
    "def draw_digit(data):\n",
    "    size = 28\n",
    "    n = data.shape[0]\n",
    "    plt.figure(figsize=(n, 2))\n",
    "    cnt = 1\n",
    "    for idx in np.arange(n):\n",
    "        plt.subplot(1, n, cnt)\n",
    "        X, Y = np.meshgrid(range(size),range(size))\n",
    "        Z = data[idx].reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "        Z = Z[::-1,:]             # flip vertical\n",
    "        plt.xlim(0,27)\n",
    "        plt.ylim(0,27)\n",
    "        plt.pcolor(X, Y, Z)\n",
    "        plt.gray()\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()\n",
    "\n",
    "# いくつかプロット\n",
    "def draw_digit_multi(data, n=10):\n",
    "    # サンプラー\n",
    "    indexes = np.random.permutation( len(data) )[:n]\n",
    "    # \n",
    "    size = 28\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    # plot\n",
    "    cnt = 1\n",
    "    for idx in indexes:\n",
    "        plt.subplot(1, n, cnt)\n",
    "        X, Y = np.meshgrid(range(size),range(size))\n",
    "        Z = data[idx].reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "        Z = Z[::-1,:]\n",
    "        plt.xlim(0, size-1)\n",
    "        plt.ylim(0, size-1)\n",
    "        plt.pcolor(X, Y, Z)\n",
    "        plt.gray()\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = data.load_mnist_data()\n",
    "# 70,000の手書き数字データ\n",
    "# いくつかplotしてみる\n",
    "#idxs = draw_digit_multi(mnist['data'])\n",
    "#print \"labels : \"\n",
    "#print mnist['target'][idxs]\n",
    "\n",
    "# 正規化\n",
    "mnist['data'] = mnist['data'].astype(np.float32)\n",
    "mnist['data'] /= 255\n",
    "mnist['target'] = mnist['target'].astype(np.int32)\n",
    "# 訓練データとテストデータに分割\n",
    "N = 60000\n",
    "x_train, x_test = np.split(mnist['data'],   [N])\n",
    "y_train, y_test = np.split(mnist['target'], [N])\n",
    "N_test = y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100 # ミニバッチのサイズ\n",
    "n_epoch = 20     # epoch数\n",
    "n_latent = 100   # 潜在変数の次元(DCGANで言うところのプライヤーベクトルの次元)\n",
    "n_h = 500   # 隠れ層のサイズ\n",
    "beta = 0.1   # KL正則化項の重み\n",
    "\n",
    "# Optimizer\n",
    "al = 0.001\n",
    "b1 = 0.9\n",
    "b2 = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義\n",
    "* 公式exampleではnet.pyとして別ファイルになっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(chainer.Chain):\n",
    "    \"\"\"Variational AutoEncoder\"\"\"\n",
    "    def __init__(self, n_in, n_latent, n_h):\n",
    "        super(VAE, self).__init__(\n",
    "            ## ネットワーク構造の定義\n",
    "            # encoder\n",
    "            le1=L.Linear(n_in, n_h),\n",
    "            le2_mu=L.Linear(n_h, n_latent),\n",
    "            le2_ln_var=L.Linear(n_h, n_latent),\n",
    "            # decoder\n",
    "            ld1=L.Linear(n_latent, n_h),\n",
    "            ld2=L.Linear(n_h, n_in),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, sigmoid=True):\n",
    "        \"\"\"AutoEncoder\"\"\"\n",
    "        # 下記、encodeとdecodeの中身をこの中に書いても良いがencodeとｄｅｃｏｄｅは他でも使うので再利用性を高めるために\n",
    "        return self.decode(self.encode(x)[0], sigmoid)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # 推論モデル, 中間表現のベクトルqを学習\n",
    "        h1 = F.tanh(self.le1(x))\n",
    "        mu = self.le2_mu(h1)\n",
    "        ln_var = self.le2_ln_var(h1)  # log(sigma**2)\n",
    "        return mu, ln_var\n",
    "\n",
    "    def decode(self, z, sigmoid=True):\n",
    "        # 中間表現ベクトルqを入力として(z), 画像を生成\n",
    "        h1 = F.tanh(self.ld1(z))\n",
    "        h2 = self.ld2(h1)\n",
    "        if sigmoid:\n",
    "            return F.sigmoid(h2)\n",
    "        else:\n",
    "            return h2\n",
    "\n",
    "    def get_loss_func(self, C=1.0, k=1, train=True):\n",
    "        \"\"\"Get loss function of VAE.\n",
    "        Args:\n",
    "            C (int): Usually this is 1.0. Can be changed to control the\n",
    "                second term of ELBO bound, which works as regularization.\n",
    "            k (int): Number of Monte Carlo samples used in encoded vector.\n",
    "            train (bool): If true loss_function is used for training.\n",
    "        \"\"\"\n",
    "        def lf(x):\n",
    "            mu, ln_var = self.encode(x)\n",
    "            batchsize = len(mu.data)\n",
    "            # reconstruction loss\n",
    "            rec_loss = 0\n",
    "            for l in six.moves.range(k):\n",
    "                z = F.gaussian(mu, ln_var)\n",
    "                rec_loss += F.bernoulli_nll(x, self.decode(z, sigmoid=False)) / (k * batchsize)\n",
    "            self.rec_loss = rec_loss\n",
    "            self.loss = self.rec_loss + C * gaussian_kl_divergence(mu, ln_var) / batchsize\n",
    "            return self.loss\n",
    "        return lf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAEモデルとOptimizerを設定して学習の準備をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "model = VAE(784, n_latent, n_h) # VAE(n_in, n_latent, n_h)  input=28*28=784\n",
    "if gpu_flag >= 0:\n",
    "    cuda.get_device(gpu_flag).use()\n",
    "    model.to_gpu()\n",
    "xp = np if gpu_flag < 0 else cuda.cupy\n",
    "\n",
    "# Optimizerを定義する\n",
    "optimizer = optimizers.Adam(alpha=al, beta1=b1, beta2=b2)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch', 1)\n",
      "train mean loss=118.19952521, mean reconstruction loss=107.579854342\n",
      "('epoch', 2)\n",
      "train mean loss=81.6189053981, mean reconstruction loss=69.6656666819\n",
      "('epoch', 3)\n",
      "train mean loss=76.5023194758, mean reconstruction loss=64.6869656436\n",
      "('epoch', 4)\n",
      "train mean loss=73.9248562749, mean reconstruction loss=62.4371701177\n",
      "('epoch', 5)\n",
      "train mean loss=72.3587466431, mean reconstruction loss=61.1273801295\n",
      "('epoch', 6)\n",
      "train mean loss=71.349088707, mean reconstruction loss=60.3119706345\n",
      "('epoch', 7)\n",
      "train mean loss=70.6659774144, mean reconstruction loss=59.7677466774\n",
      "('epoch', 8)\n",
      "train mean loss=70.1985411199, mean reconstruction loss=59.3996922366\n",
      "('epoch', 9)\n",
      "train mean loss=69.7826072693, mean reconstruction loss=59.0646162605\n",
      "('epoch', 10)\n",
      "train mean loss=69.992949117, mean reconstruction loss=59.1703042285\n",
      "('epoch', 11)\n",
      "train mean loss=69.2069728343, mean reconstruction loss=58.6158696747\n",
      "('epoch', 12)\n",
      "train mean loss=68.9628367615, mean reconstruction loss=58.4370557022\n",
      "('epoch', 13)\n",
      "train mean loss=68.7349255498, mean reconstruction loss=58.2765415573\n",
      "('epoch', 14)\n",
      "train mean loss=68.5805346807, mean reconstruction loss=58.1716053518\n",
      "('epoch', 15)\n",
      "train mean loss=68.4199444898, mean reconstruction loss=58.0465724691\n",
      "('epoch', 16)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "for epoch in six.moves.range(1, n_epoch + 1):\n",
    "    print('epoch', epoch)\n",
    "    # training\n",
    "    ## 訓練データのsampler\n",
    "    perm = np.random.permutation(N)\n",
    "    ## lossのbuffer\n",
    "    sum_loss = 0       # total loss\n",
    "    sum_rec_loss = 0   # reconstruction loss\n",
    "    ## バッチ学習\n",
    "    for i in six.moves.range(0, N, batchsize):\n",
    "        x = chainer.Variable(xp.asarray(x_train[perm[i:i + batchsize]])) # バッチ分のデータの抽出\n",
    "        # optimizerのupdateメソッドにloss関数とデータを与える　こうすると中でいろいろやってくれる\n",
    "        #optimizer.update(model.get_loss_func(), x)\n",
    "        # 勾配を明示的に計算する場合\n",
    "        model.zerograds()\n",
    "        loss = model.get_loss_func(C=beta)(x)\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(model.loss.data) * len(x.data)\n",
    "        sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n",
    "\n",
    "    print('train mean loss={}, mean reconstruction loss={}'.format(sum_loss / N, sum_rec_loss / N))\n",
    "    loss_arr.append(float(sum_loss)/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## lossグラフ\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(range(len(loss_arr)), loss_arr, color=\"#0000FF\")\n",
    "plt.title(\"loss\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ind = [1, 3, 5, 10, 2, 0, 13, 15, 17]\n",
    "x = chainer.Variable(xp.asarray(x_train[train_ind]), volatile='on')\n",
    "x1 = model(x)\n",
    "\n",
    "print \"training image\"\n",
    "draw_digit(x_train[train_ind])\n",
    "\n",
    "print \"reconstruction image\"\n",
    "draw_digit(x1.data.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# draw images from randomly sampled z\n",
    "z = chainer.Variable(xp.random.normal(0, 1, (9, n_latent)).astype(np.float32))\n",
    "x = model.decode(z)\n",
    "#draw_digit(x.data)\n",
    "print \"decode image from random vector\"\n",
    "draw_digit(x.data.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 中間層の状態を可視化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 中間層の状態をプロットする\n",
    "def draw_weight(data):\n",
    "    # サンプラー\n",
    "    n = 100\n",
    "    indexes = np.random.permutation( len(data) )[:n]\n",
    "    size = 28\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # plot\n",
    "    cnt = 1\n",
    "    for idx in indexes:\n",
    "        plt.subplot(10, 10, cnt)\n",
    "        X, Y = np.meshgrid(range(size),range(size))\n",
    "        Z = data[idx].reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "        Z = Z[::-1,:]\n",
    "        plt.xlim(0, size-1)\n",
    "        plt.ylim(0, size-1)\n",
    "        plt.pcolor(X, Y, Z)\n",
    "        plt.gray()\n",
    "        plt.title(\"{0}\".format(idx), size=9)\n",
    "        plt.tick_params(labelbottom=\"off\")\n",
    "        plt.tick_params(labelleft=\"off\")\n",
    "        cnt+=1\n",
    "    plt.show()\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxs = draw_weight(model.le1.W.data.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 出力層の手前\n",
    "idx = draw_weight(model.ld2.W.data.get().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
